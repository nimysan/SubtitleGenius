#!/usr/bin/env python3
"""
ç®€å•çš„ Whisper æµå¼å¤„ç†ç¤ºä¾‹
å¿«é€Ÿå¼€å§‹ä½¿ç”¨ Whisper è¿›è¡Œå®æ—¶è¯­éŸ³è¯†åˆ«
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from subtitle_genius.models.transcribe_model import TranscribeModel
from subtitle_genius.models.whisper_streaming_model import WhisperStreamConfig


async def simple_whisper_example():
    """ç®€å•çš„ Whisper æµå¼å¤„ç†ç¤ºä¾‹"""
    
    print("ğŸ¤ Whisper æµå¼è¯­éŸ³è¯†åˆ«ç¤ºä¾‹")
    print("=" * 40)
    
    # 1. åˆ›å»º Whisper æµå¼æ¨¡å‹
    print("ğŸ“¦ åˆå§‹åŒ– Whisper æ¨¡å‹...")
    
    # é…ç½®å‚æ•°
    config = WhisperStreamConfig(
        chunk_duration=3.0,    # æ¯3ç§’å¤„ç†ä¸€æ¬¡
        overlap_duration=0.5,  # 0.5ç§’é‡å é¿å…æˆªæ–­
        voice_threshold=0.01   # è¯­éŸ³æ£€æµ‹é˜ˆå€¼
    )
    
    # åˆ›å»ºæ¨¡å‹ (ä½¿ç”¨ Whisper åç«¯)
    model = TranscribeModel(
        backend="whisper",
        whisper_model="base",  # å¯é€‰: tiny, base, small, medium, large
        whisper_config=config
    )
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
    if not model.is_available():
        print("âŒ Whisper ä¸å¯ç”¨ï¼Œè¯·å®‰è£…:")
        print("   pip install openai-whisper")
        return
    
    print("âœ… Whisper æ¨¡å‹å·²å‡†å¤‡å°±ç»ª")
    
    # 2. å¤„ç†éŸ³é¢‘æ–‡ä»¶ (å¦‚æœå­˜åœ¨)
    audio_file = "test_audio.wav"  # æ›¿æ¢ä¸ºä½ çš„éŸ³é¢‘æ–‡ä»¶
    
    if Path(audio_file).exists():
        print(f"\nğŸµ å¤„ç†éŸ³é¢‘æ–‡ä»¶: {audio_file}")
        
        # å¯¼å…¥æµå¤„ç†å™¨
        from subtitle_genius.stream.processor import StreamProcessor
        processor = StreamProcessor()
        
        # åˆ›å»ºæ–‡ä»¶éŸ³é¢‘æµ
        audio_stream = processor.process_file_stream(audio_file)
        
        # æµå¼è½¬å½•
        async for subtitle in model.transcribe_stream(audio_stream, language="ar"):
            print(f"ğŸ“ [{subtitle.start:.1f}s] {subtitle.text}")
    
    else:
        print(f"\nâš ï¸  éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        print("è¯·æä¾›éŸ³é¢‘æ–‡ä»¶æˆ–ä½¿ç”¨éº¦å…‹é£æ¨¡å¼")
    
    print("\nâœ… ç¤ºä¾‹å®Œæˆ")


async def microphone_example():
    """éº¦å…‹é£å®æ—¶è¯†åˆ«ç¤ºä¾‹"""
    
    print("ğŸ¤ éº¦å…‹é£å®æ—¶è¯­éŸ³è¯†åˆ«")
    print("=" * 30)
    
    # åˆ›å»ºå¿«é€Ÿå“åº”çš„é…ç½®
    config = WhisperStreamConfig(
        chunk_duration=2.0,    # æ›´çŸ­çš„å¤„ç†é—´éš”
        overlap_duration=0.3,  # è¾ƒçŸ­é‡å 
        voice_threshold=0.02   # ç¨é«˜çš„æ£€æµ‹é˜ˆå€¼
    )
    
    model = TranscribeModel(
        backend="whisper",
        whisper_model="base",
        whisper_config=config
    )
    
    if not model.is_available():
        print("âŒ Whisper ä¸å¯ç”¨")
        return
    
    try:
        from subtitle_genius.stream.processor import StreamProcessor
        processor = StreamProcessor()
        
        print("ğŸ”´ å¼€å§‹å½•éŸ³ (æŒ‰ Ctrl+C åœæ­¢)")
        print("ğŸ’¬ è¯·å¼€å§‹è¯´è¯...")
        
        # å¯åŠ¨éº¦å…‹é£
        mic_stream = processor.start_microphone_stream()
        
        # å®æ—¶è½¬å½•
        async for subtitle in model.transcribe_stream(mic_stream, language="ar"):
            print(f"ğŸ—£ï¸  {subtitle.text}")
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸  å½•éŸ³åœæ­¢")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Whisper æµå¼å¤„ç†å¿«é€Ÿå¼€å§‹")
    print("=" * 50)
    
    choice = input("é€‰æ‹©æ¨¡å¼:\n  1. æ–‡ä»¶å¤„ç†\n  2. éº¦å…‹é£å®æ—¶\nè¯·è¾“å…¥ (1/2): ").strip()
    
    if choice == "1":
        await simple_whisper_example()
    elif choice == "2":
        await microphone_example()
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ å†è§!")
    except Exception as e:
        print(f"âŒ è¿è¡Œå¤±è´¥: {e}")
        print("\nğŸ’¡ ç¡®ä¿å·²å®‰è£…ä¾èµ–:")
        print("   pip install openai-whisper")
        print("   pip install pyaudio  # ç”¨äºéº¦å…‹é£")
