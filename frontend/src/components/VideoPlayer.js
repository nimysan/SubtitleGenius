import React, { useRef, useEffect, forwardRef, useImperativeHandle, useState } from 'react';
import './VideoPlayer.css';

const VideoPlayer = forwardRef(({ videoFile, onTimeUpdate, onAudioData }, ref) => {
  const videoRef = useRef(null);
  const audioContextRef = useRef(null);
  const sourceNodeRef = useRef(null);
  const processorNodeRef = useRef(null);
  const analyserNodeRef = useRef(null);
  const [isExtracting, setIsExtracting] = useState(false);

  useImperativeHandle(ref, () => ({
    getCurrentTime: () => videoRef.current?.currentTime || 0,
    play: () => videoRef.current?.play(),
    pause: () => videoRef.current?.pause(),
    seekTo: (time) => {
      if (videoRef.current) {
        videoRef.current.currentTime = time;
      }
    },
    startAudioExtraction: () => startAudioExtraction(),
    stopAudioExtraction: () => stopAudioExtraction()
  }));

  useEffect(() => {
    if (videoFile && videoRef.current) {
      const videoUrl = URL.createObjectURL(videoFile);
      videoRef.current.src = videoUrl;
      
      return () => {
        URL.revokeObjectURL(videoUrl);
      };
    }
  }, [videoFile]);

  // å¼€å§‹éŸ³é¢‘æå–
  const startAudioExtraction = () => {
    if (!videoRef.current || isExtracting) return;
    
    try {
      setIsExtracting(true);
      
      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
      const AudioContext = window.AudioContext || window.webkitAudioContext;
      audioContextRef.current = new AudioContext();
      
      // åˆ›å»ºåª’ä½“æºèŠ‚ç‚¹
      sourceNodeRef.current = audioContextRef.current.createMediaElementSource(videoRef.current);
      
      // åˆ›å»ºåˆ†æå™¨èŠ‚ç‚¹
      analyserNodeRef.current = audioContextRef.current.createAnalyser();
      analyserNodeRef.current.fftSize = 2048;
      
      // åˆ›å»ºè„šæœ¬å¤„ç†èŠ‚ç‚¹
      const bufferSize = 4096;
      
      // æ£€æŸ¥æ˜¯å¦æ”¯æŒAudioWorkletNode
      if (audioContextRef.current.audioWorklet) {
        // ä½¿ç”¨ç°ä»£çš„AudioWorklet API
        audioContextRef.current.audioWorklet.addModule('audioProcessor.js')
          .then(() => {
            processorNodeRef.current = new AudioWorkletNode(
              audioContextRef.current,
              'audio-processor'
            );
            
            // è¿æ¥èŠ‚ç‚¹
            connectAudioNodes();
            
            // è®¾ç½®æ¶ˆæ¯å¤„ç†
            processorNodeRef.current.port.onmessage = (event) => {
              if (onAudioData && event.data.audioData) {
                onAudioData(event.data.audioData);
              }
            };
          })
          .catch(err => {
            console.error('æ— æ³•åŠ è½½AudioWorklet:', err);
            fallbackToScriptProcessor();
          });
      } else {
        // å›é€€åˆ°æ—§çš„ScriptProcessorNode
        fallbackToScriptProcessor();
      }
      
      console.log('å¼€å§‹éŸ³é¢‘æå–');
      
    } catch (error) {
      console.error('éŸ³é¢‘æå–åˆå§‹åŒ–å¤±è´¥:', error);
      stopAudioExtraction();
    }
  };
  
  // å›é€€åˆ°ScriptProcessorNode
  const fallbackToScriptProcessor = () => {
    try {
      // åˆ›å»ºè„šæœ¬å¤„ç†èŠ‚ç‚¹ - è°ƒæ•´ç¼“å†²åŒºå¤§å°ä¸º3ç§’çš„éŸ³é¢‘æ•°æ®
      const sampleRate = audioContextRef.current.sampleRate;
      const chunkDuration = 3; // 3ç§’
      const bufferSize = Math.pow(2, Math.ceil(Math.log2(sampleRate * chunkDuration))); // å‘ä¸Šå–æœ€æ¥è¿‘çš„2çš„å¹‚
      console.log(`ScriptProcessorç¼“å†²åŒºå¤§å°: ${bufferSize}ï¼Œå¯¹åº”æ—¶é•¿: ${bufferSize/sampleRate}ç§’`);
      
      processorNodeRef.current = audioContextRef.current.createScriptProcessor(
        bufferSize, 
        1, // å•å£°é“è¾“å…¥
        1  // å•å£°é“è¾“å‡º
      );
      
      // è®¾ç½®éŸ³é¢‘å¤„ç†å›è°ƒ
      processorNodeRef.current.onaudioprocess = (audioProcessingEvent) => {
        const inputBuffer = audioProcessingEvent.inputBuffer;
        const inputData = inputBuffer.getChannelData(0);
        
        // å…‹éš†æ•°æ®ï¼Œå› ä¸ºinputDataæ˜¯åªè¯»çš„
        const audioData = new Float32Array(inputData.length);
        audioData.set(inputData);
        
        // å‘é€éŸ³é¢‘æ•°æ®
        if (onAudioData) {
          console.log(`ScriptProcessorå‘é€éŸ³é¢‘æ•°æ®ï¼Œæ ·æœ¬æ•°: ${audioData.length}ï¼Œæ—¶é•¿: ${audioData.length/audioContextRef.current.sampleRate}ç§’`);
          onAudioData(audioData);
        }
      };
      
      // è¿æ¥èŠ‚ç‚¹
      connectAudioNodes();
      
    } catch (error) {
      console.error('ScriptProcessorå›é€€å¤±è´¥:', error);
      stopAudioExtraction();
    }
  };
  
  // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
  const connectAudioNodes = () => {
    if (!sourceNodeRef.current || !processorNodeRef.current || !audioContextRef.current) return;
    
    // è¿æ¥: æº -> åˆ†æå™¨ -> å¤„ç†å™¨ -> ç›®æ ‡
    sourceNodeRef.current.connect(analyserNodeRef.current);
    analyserNodeRef.current.connect(processorNodeRef.current);
    
    // ScriptProcessorNodeéœ€è¦è¿æ¥åˆ°ç›®æ ‡ï¼ŒAudioWorkletNodeä¸éœ€è¦
    if (processorNodeRef.current.constructor.name === 'ScriptProcessorNode') {
      processorNodeRef.current.connect(audioContextRef.current.destination);
    }
    
    // åŒæ—¶è¿æ¥æºåˆ°ç›®æ ‡ï¼Œç¡®ä¿éŸ³é¢‘å¯ä»¥æ’­æ”¾
    sourceNodeRef.current.connect(audioContextRef.current.destination);
  };

  // åœæ­¢éŸ³é¢‘æå–
  const stopAudioExtraction = () => {
    if (!isExtracting) return;
    
    try {
      // æ–­å¼€æ‰€æœ‰è¿æ¥
      if (sourceNodeRef.current) {
        sourceNodeRef.current.disconnect();
      }
      
      if (analyserNodeRef.current) {
        analyserNodeRef.current.disconnect();
      }
      
      if (processorNodeRef.current) {
        processorNodeRef.current.disconnect();
      }
      
      // å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close();
      }
      
      // é‡ç½®å¼•ç”¨
      sourceNodeRef.current = null;
      processorNodeRef.current = null;
      analyserNodeRef.current = null;
      audioContextRef.current = null;
      
      console.log('åœæ­¢éŸ³é¢‘æå–');
      
    } catch (error) {
      console.error('åœæ­¢éŸ³é¢‘æå–å¤±è´¥:', error);
    } finally {
      setIsExtracting(false);
    }
  };

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†èµ„æº
  useEffect(() => {
    return () => {
      stopAudioExtraction();
    };
  }, []);

  const handleTimeUpdate = () => {
    if (videoRef.current && onTimeUpdate) {
      onTimeUpdate(videoRef.current.currentTime);
    }
  };

  return (
    <div className="video-player-container">
      {videoFile ? (
        <video
          ref={videoRef}
          className="video-player"
          controls
          onTimeUpdate={handleTimeUpdate}
          onLoadedMetadata={() => {
            console.log('Video loaded:', videoFile.name);
          }}
        >
          æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè§†é¢‘æ’­æ”¾ã€‚
        </video>
      ) : (
        <div className="video-placeholder">
          <div className="placeholder-content">
            <div className="placeholder-icon">ğŸ¬</div>
            <h3>è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶</h3>
            <p>æ”¯æŒ MP4, WebM, AVI ç­‰æ ¼å¼</p>
          </div>
        </div>
      )}
    </div>
  );
});

VideoPlayer.displayName = 'VideoPlayer';

export default VideoPlayer;
