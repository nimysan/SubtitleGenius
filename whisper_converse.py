import boto3
import json
import base64
import io
import wave
import math
import time
import os
import subprocess
import tempfile
from pathlib import Path
from typing import Optional, Dict, Any, List
from io import BytesIO

def check_ffmpeg():
    """Check if FFmpeg is available in the environment."""
    try:
        result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True, check=False)
        if result.returncode == 0:
            print(f"FFmpeg found: {result.stdout.splitlines()[0] if result.stdout else 'No version info'}")
            return True
        print(f"FFmpeg command failed with return code {result.returncode}")
        return False
    except Exception as e:
        print(f"Exception checking for FFmpeg: {str(e)}")
        return False

def detect_audio_format(audio_data):
    """Detect the audio/video format based on file signatures."""
    signatures = {
        b'RIFF': 'wav',  # WAV files
        b'\xff\xfb': 'mp3',  # MP3 files
        b'\x00\x00\x00': 'mp4',  # MP4/MOV files
        b'ftyp': 'mp4',  # MP4 files
        b'ID3': 'mp3',  # MP3 files with ID3 tag
        b'OggS': 'ogg'   # OGG files
    }
    
    for sig, fmt in signatures.items():
        if audio_data.startswith(sig):
            return fmt
        if fmt == 'mp4' and sig == b'ftyp' and b'ftyp' in audio_data[:50]:
            return fmt
    
    return 'unknown'

def is_wav_format(audio_data):
    """Check if the audio data is in WAV format (starts with RIFF header)."""
    return audio_data.startswith(b'RIFF')

def convert_mp4_to_wav(mp4_data):
    """Convert MP4 audio data to WAV format using FFmpeg."""
    print(f"Converting MP4 to WAV. Input data size: {len(mp4_data)} bytes")
    
    tmp_dir = tempfile.gettempdir()
    timestamp = int(time.time())
    mp4_path = os.path.join(tmp_dir, f"input_{timestamp}.mp4")
    wav_path = os.path.join(tmp_dir, f"output_{timestamp}.wav")
    
    try:
        # Write the MP4 data to a file
        with open(mp4_path, 'wb') as mp4_file:
            mp4_file.write(mp4_data)
        
        print(f"MP4 file written to {mp4_path}")
        
        # Check FFmpeg availability
        ffmpeg_available = check_ffmpeg()
        
        if ffmpeg_available:
            # Use FFmpeg for conversion
            cmd = ['ffmpeg', '-i', mp4_path, '-vn', '-acodec', 'pcm_s16le', '-ar', '44100', '-ac', '2', wav_path]
            print(f"Running command: {' '.join(cmd)}")
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode == 0:
                print("FFmpeg conversion successful")
                with open(wav_path, 'rb') as wav_file:
                    wav_data = wav_file.read()
                    print(f"WAV data size: {len(wav_data)} bytes")
                return wav_data
            else:
                print(f"FFmpeg error: {result.stderr}")
                raise Exception(f"FFmpeg conversion failed: {result.stderr}")
        else:
            # Fallback: create minimal WAV header
            print("Using fallback WAV header creation")
            sample_rate = 44100
            channels = 2
            bits_per_sample = 16
            
            header = BytesIO()
            header.write(b'RIFF')
            header.write((36 + len(mp4_data)).to_bytes(4, 'little'))
            header.write(b'WAVE')
            header.write(b'fmt ')
            header.write((16).to_bytes(4, 'little'))
            header.write((1).to_bytes(2, 'little'))
            header.write((channels).to_bytes(2, 'little'))
            header.write((sample_rate).to_bytes(4, 'little'))
            header.write((sample_rate * channels * bits_per_sample // 8).to_bytes(4, 'little'))
            header.write((channels * bits_per_sample // 8).to_bytes(2, 'little'))
            header.write((bits_per_sample).to_bytes(2, 'little'))
            header.write(b'data')
            header.write((len(mp4_data)).to_bytes(4, 'little'))
            
            # Extract audio data from MP4 if possible
            data_start = 0
            for i in range(len(mp4_data) - 4):
                if mp4_data[i:i+4] == b'mdat':
                    data_start = i + 8
                    break
            
            audio_data = mp4_data[data_start:] if data_start > 0 else mp4_data
            max_size = sample_rate * channels * bits_per_sample // 8 * 30  # 30 seconds max
            audio_data = audio_data[:max_size] if len(audio_data) > max_size else audio_data
            
            wav_data = header.getvalue() + audio_data
            print(f"Created WAV with manual header. Size: {len(wav_data)} bytes")
            return wav_data
            
    except Exception as e:
        print(f"Error in convert_mp4_to_wav: {str(e)}")
        raise
    finally:
        # Cleanup temporary files
        try:
            if os.path.exists(mp4_path):
                os.remove(mp4_path)
            if os.path.exists(wav_path):
                os.remove(wav_path)
        except Exception as cleanup_error:
            print(f"Error during cleanup: {cleanup_error}")

def chunk_audio(audio_data, chunk_duration_seconds=30):
    """Split wave audio from BytesIO into chunks."""
    try:
        print(f"Starting audio chunking. Input data size: {len(audio_data)} bytes")
        
        # Check audio format
        audio_format = detect_audio_format(audio_data)
        print(f"Detected audio format: {audio_format}")
        
        # Convert to WAV if needed
        if not is_wav_format(audio_data):
            print(f"Input is not WAV format (detected as {audio_format}), attempting conversion...")
            audio_data = convert_mp4_to_wav(audio_data)
            print(f"Conversion completed. WAV data size: {len(audio_data)} bytes")
        
        # Create a BytesIO object from the audio data
        wav_buffer = BytesIO(audio_data)
        
        with wave.open(wav_buffer, 'rb') as wav_file:
            # Get file properties
            n_channels = wav_file.getnchannels()
            sampwidth = wav_file.getsampwidth()
            framerate = wav_file.getframerate()
            n_frames = wav_file.getnframes()
            
            print(f"WAV properties: channels={n_channels}, sampwidth={sampwidth}, framerate={framerate}, frames={n_frames}")
            
            # Calculate frames per chunk
            frames_per_chunk = chunk_duration_seconds * framerate
            
            # Adjust chunk size for SageMaker payload limits (2MB safe limit)
            max_payload_size = 2 * 1024 * 1024
            bytes_per_frame = n_channels * sampwidth
            estimated_chunk_size = frames_per_chunk * bytes_per_frame + 44
            
            if estimated_chunk_size > max_payload_size:
                size_ratio = max_payload_size / estimated_chunk_size
                adjusted_chunk_duration = int(chunk_duration_seconds * size_ratio * 0.8)
                frames_per_chunk = adjusted_chunk_duration * framerate
                print(f"Adjusted chunk duration to {adjusted_chunk_duration} seconds")
            
            n_chunks = math.ceil(n_frames / frames_per_chunk)
            print(f"Audio will be split into {n_chunks} chunks")
            
            chunks = []
            for i in range(n_chunks):
                try:
                    # Read chunk of frames
                    start_frame = i * frames_per_chunk
                    wav_file.setpos(int(start_frame))
                    chunk_frames = wav_file.readframes(int(frames_per_chunk))
                    
                    # Create a new wave file in memory for this chunk
                    chunk_buffer = BytesIO()
                    with wave.open(chunk_buffer, 'wb') as chunk_wav:
                        chunk_wav.setnchannels(n_channels)
                        chunk_wav.setsampwidth(sampwidth)
                        chunk_wav.setframerate(framerate)
                        chunk_wav.writeframes(chunk_frames)
                    
                    chunk_data = chunk_buffer.getvalue()
                    print(f"Chunk {i+1}/{n_chunks} created, size: {len(chunk_data)} bytes")
                    chunks.append(chunk_data)
                except Exception as chunk_error:
                    print(f"Error processing chunk {i+1}: {chunk_error}")
            
            # Filter out chunks that are too small
            valid_chunks = [chunk for chunk in chunks if len(chunk) > 44]
            print(f"Successfully created {len(valid_chunks)} valid chunks")
            return valid_chunks
            
    except Exception as e:
        print(f"Error in chunk_audio: {str(e)}")
        return []

def transcribe_chunk(sagemaker_client, chunk_data, endpoint_name, language="en", task="transcribe"):
    """Transcribe a single audio chunk using SageMaker runtime with Whisper endpoint."""
    try:
        print(f"Using SageMaker endpoint: {endpoint_name}")
        print(f"Sending request with audio size: {len(chunk_data)} bytes")
        
        # Convert audio to hex string (format expected by Whisper endpoints)
        hex_audio = chunk_data.hex()
        
        # Create payload for Whisper endpoint
        payload = {
            "audio_input": hex_audio,
            "language": language,
            "task": task,
            "top_p": 0.9
        }
        
        # Invoke the SageMaker endpoint
        response = sagemaker_client.invoke_endpoint(
            EndpointName=endpoint_name,
            ContentType='application/json',
            Body=json.dumps(payload)
        )
        
        # Parse the response
        response_body = json.loads(response['Body'].read().decode('utf-8'))
        print(f"Response received from SageMaker endpoint")
        
        return response_body
        
    except Exception as e:
        print(f"Error invoking SageMaker endpoint: {str(e)}")
        raise
    """æ‰“å°messagesçš„æ ‘å½¢ç»“æ„ï¼Œéšè—éŸ³é¢‘æ•°æ®"""
    def print_tree(obj, prefix="", is_last=True, indent="  "):
        # æ‰“å°å½“å‰èŠ‚ç‚¹
        branch = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
        print(f"{prefix}{branch}", end="")
        
        if isinstance(obj, dict):
            if "audio" in obj:
                print("<audio>")
            elif "source" in obj and "data" in obj["source"]:
                print("<audio_data>")
            else:
                print("{")
                new_prefix = prefix + (indent if is_last else "â”‚   ")
                items = list(obj.items())
                for i, (key, value) in enumerate(items):
                    print(f"{new_prefix}â”œâ”€â”€ {key}: ", end="")
                    if isinstance(value, (dict, list)):
                        print()
                        print_tree(value, new_prefix + indent, i == len(items) - 1)
                    else:
                        if isinstance(value, str) and len(value) > 50:
                            print(f"{value[:50]}...")
                        else:
                            print(value)
                if not items:
                    print("}")
        elif isinstance(obj, list):
            print("[")
            new_prefix = prefix + (indent if is_last else "â”‚   ")
            for i, item in enumerate(obj):
                print_tree(item, new_prefix, i == len(obj) - 1)
            if not obj:
                print(f"{prefix}{indent}]")
        else:
            if isinstance(obj, str) and len(obj) > 50:
                print(f"{obj[:50]}...")
            else:
                print(obj)

    print("\nMessages Tree Structure:")
    print_tree(messages)

class WhisperSageMakerClient:
    """ä½¿ç”¨SageMaker Runtimeè°ƒç”¨è‡ªå®šä¹‰Whisper Turboç«¯ç‚¹çš„å®¢æˆ·ç«¯"""
    
    def __init__(self, 
                 endpoint_name: str,
                 region_name: str = "us-east-1"):
        """
        åˆå§‹åŒ–Whisper SageMakerå®¢æˆ·ç«¯
        
        Args:
            endpoint_name: SageMakerç«¯ç‚¹åç§°
            region_name: AWSåŒºåŸŸ
        """
        self.endpoint_name = endpoint_name
        self.region_name = region_name
        
        try:
            self.sagemaker_runtime = boto3.client("sagemaker-runtime", region_name=region_name)
            print(f"âœ… æˆåŠŸåˆå§‹åŒ–SageMaker Runtimeå®¢æˆ·ç«¯ï¼ŒåŒºåŸŸ: {region_name}")
            print(f"ğŸ¯ ç«¯ç‚¹åç§°: {endpoint_name}")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–SageMaker Runtimeå®¢æˆ·ç«¯æ—¶å‡ºé”™: {e}")
            print("è¯·ç¡®ä¿æ‚¨å·²é…ç½®AWSå‡­è¯")
            raise
    
    def load_audio_file(self, audio_path: str) -> bytes:
        """
        åŠ è½½éŸ³é¢‘æ–‡ä»¶å¹¶è½¬æ¢ä¸ºå­—èŠ‚æ•°æ®
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            éŸ³é¢‘æ–‡ä»¶çš„å­—èŠ‚æ•°æ®
        """
        audio_path = Path(audio_path)
        if not audio_path.exists():
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        with open(audio_path, 'rb') as f:
            audio_data = f.read()
        
        print(f"ğŸ“ åŠ è½½éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {len(audio_data)} bytes")
        
        return audio_data
    
    def get_audio_info(self, audio_data: bytes) -> Dict[str, Any]:
        """
        è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
        
        Args:
            audio_data: éŸ³é¢‘å­—èŠ‚æ•°æ®
            
        Returns:
            éŸ³é¢‘ä¿¡æ¯å­—å…¸
        """
        try:
            # å°è¯•è§£æWAVæ–‡ä»¶å¤´
            audio_io = io.BytesIO(audio_data)
            with wave.open(audio_io, 'rb') as wav_file:
                info = {
                    "format": "WAV",
                    "channels": wav_file.getnchannels(),
                    "sample_rate": wav_file.getframerate(),
                    "duration": wav_file.getnframes() / wav_file.getframerate(),
                    "bit_depth": wav_file.getsampwidth() * 8
                }
                return info
        except:
            # å¦‚æœä¸æ˜¯WAVæ–‡ä»¶ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
            return {
                "format": "Unknown",
                "size_bytes": len(audio_data)
            }
    
    def transcribe_audio(self, 
                        audio_path: str,
                        language: str = "ar",
                        task: str = "transcribe",
                        chunk_duration: int = 30) -> Dict[str, Any]:
        """
        ä½¿ç”¨SageMaker Runtimeè½¬å½•éŸ³é¢‘
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç  (é»˜è®¤: ar - Arabic)
            task: ä»»åŠ¡ç±»å‹ ("transcribe" æˆ– "translate")
            chunk_duration: éŸ³é¢‘åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            è½¬å½•ç»“æœå­—å…¸
        """
        try:
            start_time = time.time()
            
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            audio_data = self.load_audio_file(audio_path)
            audio_info = self.get_audio_info(audio_data)
            
            print(f"ğŸµ éŸ³é¢‘ä¿¡æ¯: {audio_info}")
            
            # å°†éŸ³é¢‘åˆ†å—
            print(f"ğŸ”ª å¼€å§‹éŸ³é¢‘åˆ†å—ï¼Œå—æ—¶é•¿: {chunk_duration}ç§’")
            chunks = chunk_audio(audio_data, chunk_duration)
            
            if not chunks:
                raise Exception("éŸ³é¢‘åˆ†å—å¤±è´¥ï¼Œæ— æ³•å¤„ç†")
            
            print(f"ğŸ“¦ æˆåŠŸåˆ›å»º {len(chunks)} ä¸ªéŸ³é¢‘å—")
            
            # å¤„ç†æ¯ä¸ªéŸ³é¢‘å—
            all_transcriptions = []
            chunk_timings = []
            cumulative_duration = 0
            
            for i, chunk_data in enumerate(chunks, 1):
                print(f"ğŸ¯ å¤„ç†éŸ³é¢‘å— {i}/{len(chunks)}")
                
                try:
                    # è®¡ç®—æ—¶é—´æˆ³
                    chunk_start = cumulative_duration
                    chunk_end = chunk_start + chunk_duration
                    cumulative_duration = chunk_end
                    
                    # è½¬å½•å•ä¸ªå—
                    result = transcribe_chunk(
                        self.sagemaker_runtime, 
                        chunk_data, 
                        self.endpoint_name,
                        language=self._convert_language_code(language),
                        task=task
                    )
                    
                    all_transcriptions.append(result)
                    chunk_timings.append((chunk_start, chunk_end))
                    
                    print(f"âœ… éŸ³é¢‘å— {i} è½¬å½•å®Œæˆ")
                    
                except Exception as e:
                    print(f"âŒ å¤„ç†éŸ³é¢‘å— {i} æ—¶å‡ºé”™: {str(e)}")
                    # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªå—
                    all_transcriptions.append({"text": f"[å— {i} è½¬å½•å¤±è´¥]"})
                    chunk_timings.append((chunk_start, chunk_start + chunk_duration))
            
            # åˆå¹¶è½¬å½•ç»“æœ
            full_transcription = self._combine_transcriptions(all_transcriptions, chunk_timings)
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            result = {
                "transcription": full_transcription,
                "language": language,
                "task": task,
                "audio_info": audio_info,
                "chunks_processed": len(chunks),
                "chunk_timings": chunk_timings,
                "metrics": {
                    "processing_time_seconds": round(processing_time, 2),
                    "chunks_count": len(chunks),
                    "average_chunk_time": round(processing_time / len(chunks), 2) if chunks else 0
                }
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ è½¬å½•éŸ³é¢‘æ—¶å‡ºé”™: {str(e)}")
            return {
                "error": str(e),
                "transcription": None
            }
    
    def _convert_language_code(self, language: str) -> str:
        """è½¬æ¢è¯­è¨€ä»£ç ä¸ºWhisperæ”¯æŒçš„æ ¼å¼"""
        language_map = {
            "ar": "arabic",
            "ar-SA": "arabic", 
            "ar-AE": "arabic",
            "en": "english",
            "en-US": "english",
            "en-GB": "english",
            "zh": "chinese",
            "zh-CN": "chinese",
            "ja": "japanese",
            "ko": "korean",
            "fr": "french",
            "de": "german",
            "es": "spanish",
            "ru": "russian"
        }
        return language_map.get(language, "english")
    
    def _combine_transcriptions(self, transcriptions: List[Dict], timings: List[tuple]) -> str:
        """åˆå¹¶å¤šä¸ªè½¬å½•ç»“æœ"""
        combined_text = []
        
        for i, (result, (start_time, end_time)) in enumerate(zip(transcriptions, timings)):
            if isinstance(result, dict) and 'text' in result:
                text = result['text'] if isinstance(result['text'], str) else ' '.join(result['text'])
            elif isinstance(result, str):
                text = result
            else:
                text = f"[å— {i+1} æ— æ³•è§£æ]"
            
            # æ¸…ç†æ–‡æœ¬
            text = text.strip()
            if text:
                combined_text.append(text)
        
        return ' '.join(combined_text)
    
    def batch_transcribe(self, 
                        audio_files: List[str],
                        language: str = "ar",
                        task: str = "transcribe",
                        chunk_duration: int = 30) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡è½¬å½•éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_files: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            language: è¯­è¨€ä»£ç 
            task: ä»»åŠ¡ç±»å‹
            chunk_duration: éŸ³é¢‘åˆ†å—æ—¶é•¿
            
        Returns:
            è½¬å½•ç»“æœåˆ—è¡¨
        """
        results = []
        
        for i, audio_file in enumerate(audio_files, 1):
            print(f"\nğŸ“ å¤„ç†æ–‡ä»¶ {i}/{len(audio_files)}: {audio_file}")
            result = self.transcribe_audio(audio_file, language, task, chunk_duration)
            result["file_path"] = audio_file
            results.append(result)
        
        return results

def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    # é…ç½®å‚æ•°
    ENDPOINT_NAME = "endpoint-quick-start-z9afg"  # æ›¿æ¢ä¸ºä½ çš„SageMakerç«¯ç‚¹åç§°
    REGION_NAME = "us-east-1"
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = WhisperSageMakerClient(
        endpoint_name=ENDPOINT_NAME,
        region_name=REGION_NAME
    )
    
    # ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    audio_files = [
        # "/Users/yexw/PycharmProjects/SubtitleGenius/test.wav",
        "/Users/yexw/PycharmProjects/SubtitleGenius/ar_football_mono.wav"
    ]
    
    # å•ä¸ªæ–‡ä»¶è½¬å½•ç¤ºä¾‹
    print("=" * 60)
    print("ğŸ¤ å•ä¸ªæ–‡ä»¶è½¬å½•ç¤ºä¾‹ (SageMaker)")
    print("=" * 60)
    
    if Path(audio_files[0]).exists():
        result = client.transcribe_audio(
            audio_path=audio_files[0],
            language="ar",  # Arabic
            task="transcribe",
            chunk_duration=30
        )
        
        if result.get("transcription"):
            print(f"âœ… è½¬å½•æˆåŠŸ:")
            print(f"ğŸ“ æ–‡æœ¬: {result['transcription']}")
            print(f"â±ï¸  å¤„ç†æ—¶é—´: {result['metrics']['processing_time_seconds']}ç§’")
            print(f"ğŸ“¦ å¤„ç†å—æ•°: {result['metrics']['chunks_count']}")
        else:
            print(f"âŒ è½¬å½•å¤±è´¥: {result.get('error')}")
    
    # æ‰¹é‡è½¬å½•ç¤ºä¾‹
    print("\n" + "=" * 60)
    print("ğŸ“š æ‰¹é‡è½¬å½•ç¤ºä¾‹")
    print("=" * 60)
    
    existing_files = [f for f in audio_files if Path(f).exists()]
    if existing_files:
        results = client.batch_transcribe(
            audio_files=existing_files,
            language="ar",
            task="transcribe",
            chunk_duration=30
        )
        
        for i, result in enumerate(results, 1):
            print(f"\nğŸ“„ æ–‡ä»¶ {i}: {Path(result['file_path']).name}")
            if result.get("transcription"):
                print(f"âœ… è½¬å½•: {result['transcription'][:100]}...")
                print(f"ğŸ“¦ å—æ•°: {result.get('chunks_processed', 'N/A')}")
            else:
                print(f"âŒ é”™è¯¯: {result.get('error')}")
    
    # ç¿»è¯‘ç¤ºä¾‹
    print("\n" + "=" * 60)
    print("ğŸŒ ç¿»è¯‘ç¤ºä¾‹")
    print("=" * 60)
    
    if Path(audio_files[0]).exists():
        result = client.transcribe_audio(
            audio_path=audio_files[0],
            language="ar",
            task="translate",  # ç¿»è¯‘ä»»åŠ¡
            chunk_duration=30
        )
        
        if result.get("transcription"):
            print(f"âœ… ç¿»è¯‘æˆåŠŸ:")
            print(f"ğŸ”„ ç»“æœ: {result['transcription']}")

# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™æ—§çš„ç±»åä½œä¸ºåˆ«å
WhisperConverseClient = WhisperSageMakerClient

if __name__ == "__main__":
    main()
