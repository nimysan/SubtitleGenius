"""
Voice Activity Detection (VAD) å¤„ç†å™¨
åŸºäºSilero VADæ¨¡å‹çš„æµå¼è¯­éŸ³æ´»åŠ¨æ£€æµ‹
"""

import os
import sys
import time
import numpy as np
import torch
from typing import Iterator, List, Dict, Any, Optional, Callable
from loguru import logger
from collections import deque

# æ·»åŠ whisper_streamingç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), 'whisper_streaming'))
from silero_vad_iterator import FixedVADIterator


class VACProcessor:
    """
    Voice Activity Detection å¤„ç†å™¨
    
    åŸºäºSilero VADæ¨¡å‹çš„æµå¼è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼Œæ”¯æŒå®æ—¶éŸ³é¢‘æµå¤„ç†
    """
    
    def __init__(
        self,
        threshold: float = 0.3,
        min_silence_duration_ms: int = 300,
        speech_pad_ms: int = 100,
        sample_rate: int = 16000,
        processing_chunk_size: int = 512,
        no_audio_input_threshold: float = 0.5,
        on_speech_segment: Optional[Callable[[Dict[str, Any]], None]] = None
    ):
        """
        åˆå§‹åŒ–VACå¤„ç†å™¨
        
        Args:
            threshold: è¯­éŸ³æ£€æµ‹é˜ˆå€¼ (0.0-1.0)
            min_silence_duration_ms: æœ€å°é™éŸ³æŒç»­æ—¶é—´(ms)
            speech_pad_ms: è¯­éŸ³æ®µå¡«å……æ—¶é—´(ms)
            sample_rate: éŸ³é¢‘é‡‡æ ·ç‡
            processing_chunk_size: å¤„ç†å—å¤§å°ï¼Œå¿…é¡»æ˜¯512çš„æ•´æ•°å€
            no_audio_input_threshold: æ— éŸ³é¢‘è¾“å…¥é˜ˆå€¼(ç§’)
            on_speech_segment: è¯­éŸ³æ®µæ£€æµ‹å®Œæˆæ—¶çš„å›è°ƒå‡½æ•°
        """
        self.threshold = threshold
        self.min_silence_duration_ms = min_silence_duration_ms
        self.speech_pad_ms = speech_pad_ms
        self.sample_rate = sample_rate
        self.processing_chunk_size = processing_chunk_size
        self.no_audio_input_threshold = no_audio_input_threshold
        self.on_speech_segment = on_speech_segment
        
        # éªŒè¯å¤„ç†å—å¤§å°
        if self.processing_chunk_size % 512 != 0:
            raise ValueError(
                f"processing_chunk_sizeå¿…é¡»æ˜¯512çš„æ•´æ•°å€ï¼å½“å‰å€¼ä¸º{self.processing_chunk_size}ã€‚"
                f"æ¨èå€¼ï¼š512, 1024, 1536, 2048ç­‰ã€‚"
            )
        
        # åˆå§‹åŒ–æ¨¡å‹å’ŒVADè¿­ä»£å™¨
        self._model = None
        self._vad_iterator = None
        
        # éŸ³é¢‘ç¼“å­˜å’ŒçŠ¶æ€è·Ÿè¸ª
        self._audio_buffer = deque()  # å­˜å‚¨éŸ³é¢‘æ•°æ®
        self._current_start_time = None  # å½“å‰è¯­éŸ³æ®µçš„å¼€å§‹æ—¶é—´
        self._current_start_sample = None  # å½“å‰è¯­éŸ³æ®µçš„å¼€å§‹æ ·æœ¬ä½ç½®
        
        logger.info(f"VACProcessor initialized with parameters:")
        logger.info(f"  threshold: {self.threshold}")
        logger.info(f"  min_silence_duration_ms: {self.min_silence_duration_ms}")
        logger.info(f"  speech_pad_ms: {self.speech_pad_ms}")
        logger.info(f"  sample_rate: {self.sample_rate}")
        logger.info(f"  processing_chunk_size: {self.processing_chunk_size}")
        logger.info(f"  no_audio_input_threshold: {self.no_audio_input_threshold}")
    
    def _load_model(self):
        """åŠ è½½Silero VADæ¨¡å‹"""
        if self._model is None:
            logger.info("Loading Silero VAD model...")
            self._model, _ = torch.hub.load(
                repo_or_dir='snakers4/silero-vad',
                model='silero_vad'
            )
            logger.info("Silero VAD model loaded successfully")
        return self._model
    
    def _create_vad_iterator(self):
        """åˆ›å»ºVADè¿­ä»£å™¨"""
        if self._vad_iterator is None:
            model = self._load_model()
            self._vad_iterator = FixedVADIterator(
                model=model,
                threshold=self.threshold,
                sampling_rate=self.sample_rate,
                min_silence_duration_ms=self.min_silence_duration_ms,
                speech_pad_ms=self.speech_pad_ms
            )
            logger.info("VAD iterator created successfully")
        return self._vad_iterator
    
    def reset_vad_state(self):
        """é‡ç½®VADçŠ¶æ€"""
        if self._vad_iterator is not None:
            self._vad_iterator.reset_states()
            logger.debug("VAD state reset")
    
    def process_streaming_audio(
        self, 
        audio_stream: Iterator[np.ndarray],
        return_segments: bool = True
    ) -> List[Dict[str, Any]]:
        """
        å¤„ç†æµå¼éŸ³é¢‘æ•°æ®ï¼Œè¿›è¡Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹
        
        Args:
            audio_stream: éŸ³é¢‘æµè¿­ä»£å™¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯numpyæ•°ç»„
            return_segments: æ˜¯å¦è¿”å›è¯­éŸ³æ®µæ ¼å¼ï¼ˆåŒ…å«startã€endã€durationï¼‰
            
        Returns:
            è¯­éŸ³æ£€æµ‹ç»“æœåˆ—è¡¨
            - å¦‚æœreturn_segments=True: [{'start': float, 'end': float, 'duration': float}, ...]
            - å¦‚æœreturn_segments=False: [{'start': float}, {'end': float}, ...]
        """
        logger.info("å¼€å§‹æµå¼VADå¤„ç†")
        logger.info(f"ä¸ºé¿å…VADæ—¶é—´æˆ³è†¨èƒ€é—®é¢˜ï¼Œè¯·ç¡®ä¿éŸ³é¢‘æµä¸­çš„å—å¤§å°æ˜¯512çš„æ•´æ•°å€")
        
        # åˆ›å»ºVADè¿­ä»£å™¨
        vad = self._create_vad_iterator()
        
        # å¤„ç†å˜é‡
        results = []
        last_audio_time = time.time()
        total_samples_processed = 0
        stream_ended = False
        
        # é‡ç½®éŸ³é¢‘ç¼“å­˜å’ŒçŠ¶æ€
        self._audio_buffer.clear()
        self._current_start_time = None
        self._current_start_sample = None
        
        logger.info(f"å¼€å§‹å¤„ç†éŸ³é¢‘æµï¼Œå‚æ•°:")
        logger.info(f"  threshold={self.threshold}")
        logger.info(f"  min_silence_duration_ms={self.min_silence_duration_ms}")
        logger.info(f"  speech_pad_ms={self.speech_pad_ms}")
        logger.info(f"  no_audio_input_threshold={self.no_audio_input_threshold}ç§’")
        
        try:
            # å¤„ç†æµå¼éŸ³é¢‘
            for audio_chunk in audio_stream:
                # æ›´æ–°æœ€åæ¥æ”¶éŸ³é¢‘çš„æ—¶é—´
                last_audio_time = time.time()
                
                # å°†éŸ³é¢‘å—æ·»åŠ åˆ°ç¼“å­˜
                self._audio_buffer.append((audio_chunk.copy(), total_samples_processed))
                
                # å¤„ç†éŸ³é¢‘å—
                for i in range(0, len(audio_chunk), self.processing_chunk_size):
                    chunk = audio_chunk[i:i+self.processing_chunk_size]
                    
                    # å¦‚æœéœ€è¦ï¼Œç”¨é›¶å¡«å……
                    if len(chunk) < self.processing_chunk_size:
                        chunk = np.pad(chunk, (0, self.processing_chunk_size - len(chunk)), 'constant')
                    
                    # ä½¿ç”¨VADè¿­ä»£å™¨å¤„ç†å—
                    result = vad(chunk, return_seconds=True)
                    
                    total_samples_processed += len(chunk)
                    
                    if result:
                        print(f"------->>>vad result is {result}")
                        results.append(result)
                        
                        # ğŸ¯ å…³é”®é€»è¾‘ï¼šå¤„ç†startå’Œendäº‹ä»¶
                        if 'start' in result:
                            # åªæœ‰åœ¨æ²¡æœ‰æ´»è·ƒè¯­éŸ³æ®µæ—¶æ‰è®°å½•æ–°çš„å¼€å§‹
                            if self._current_start_time is None:
                                self._current_start_time = result['start']
                                self._current_start_sample = int(result['start'] * self.sample_rate)
                                logger.info(f"æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹: {self._current_start_time:.2f}s")
                            else:
                                # å¦‚æœå·²ç»æœ‰æ´»è·ƒçš„è¯­éŸ³æ®µï¼Œå¿½ç•¥æ–°çš„startäº‹ä»¶
                                logger.debug(f"å¿½ç•¥é‡å¤çš„startäº‹ä»¶: {result['start']:.2f}s (å½“å‰æ´»è·ƒæ®µ: {self._current_start_time:.2f}s)")
                            
                        elif 'end' in result and self._current_start_time is not None:
                            # æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼Œå‘å°„äº‹ä»¶
                            end_time = result['end']
                            end_sample = int(end_time * self.sample_rate)
                            
                            # æå–å¯¹åº”çš„éŸ³é¢‘æ•°æ®
                            audio_bytes = self._extract_audio_segment(
                                self._current_start_sample, 
                                end_sample
                            )
                            
                            # åˆ›å»ºè¯­éŸ³æ®µäº‹ä»¶æ•°æ®
                            speech_segment = {
                                'start': self._current_start_time,
                                'end': end_time,
                                'duration': end_time - self._current_start_time,
                                'audio_bytes': audio_bytes,
                                'sample_rate': self.sample_rate
                            }
                            
                            logger.info(f"æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ: {end_time:.2f}s, æ—¶é•¿: {speech_segment['duration']:.2f}s")
                            
                            # ğŸš€ å‘å°„äº‹ä»¶ - ç¡®ä¿åªè§¦å‘ä¸€æ¬¡
                            if self.on_speech_segment:
                                try:
                                    self.on_speech_segment(speech_segment)
                                    logger.debug(f"âœ… è¯­éŸ³æ®µäº‹ä»¶å·²è§¦å‘: {self._current_start_time:.2f}s-{end_time:.2f}s")
                                except Exception as e:
                                    logger.error(f"äº‹ä»¶å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
                            
                            # ğŸ”§ é‡è¦ï¼šç«‹å³é‡ç½®çŠ¶æ€ï¼Œé˜²æ­¢é‡å¤è§¦å‘
                            self._current_start_time = None
                            self._current_start_sample = None
                            
                        elif 'end' in result and self._current_start_time is None:
                            # æ”¶åˆ°endäº‹ä»¶ä½†æ²¡æœ‰å¯¹åº”çš„startäº‹ä»¶ï¼Œè®°å½•è­¦å‘Š
                            logger.warning(f"æ”¶åˆ°å­¤ç«‹çš„endäº‹ä»¶: {result['end']:.2f}s (æ²¡æœ‰å¯¹åº”çš„startäº‹ä»¶)")
                
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æ— éŸ³é¢‘è¾“å…¥é˜ˆå€¼
                if time.time() - last_audio_time > self.no_audio_input_threshold:
                    stream_ended = True
                    break
            
            # æ ‡è®°æµå·²ç»“æŸ
            stream_ended = True
            
        except Exception as e:
            print(f"æµå¤„ç†ä¸­æ–­: {e}")
            stream_ended = True
        
        # ğŸ”§ ä¿®å¤ï¼šéŸ³é¢‘æµç»“æŸæ—¶çš„å¤„ç†
        if stream_ended:
            print(f"éŸ³é¢‘æµå·²ç»“æŸï¼Œæ­£åœ¨è¿›è¡Œæœ€ç»ˆå¤„ç†...")
            
            # å¦‚æœVADä»å¤„äºè§¦å‘çŠ¶æ€ï¼Œå¼ºåˆ¶ç»“æŸå½“å‰è¯­éŸ³æ®µ
            if vad.triggered and self._current_start_time is not None:
                # ä½¿ç”¨å½“å‰å¤„ç†çš„æ€»æ ·æœ¬æ•°è®¡ç®—ç»“æŸæ—¶é—´
                end_time = total_samples_processed / self.sample_rate
                end_sample = total_samples_processed
                
                # æå–éŸ³é¢‘æ•°æ®
                audio_bytes = self._extract_audio_segment(
                    self._current_start_sample, 
                    end_sample
                )
                
                # åˆ›å»ºè¯­éŸ³æ®µäº‹ä»¶æ•°æ®
                speech_segment = {
                    'start': self._current_start_time,
                    'end': end_time,
                    'duration': end_time - self._current_start_time,
                    'audio_bytes': audio_bytes,
                    'sample_rate': self.sample_rate
                }
                
                results.append({'end': end_time})
                print(f"æ£€æµ‹åˆ°æœªç»“æŸçš„è¯­éŸ³æ®µï¼Œå¼ºåˆ¶ç»“æŸäº {end_time:.2f}ç§’")
                
                # ğŸš€ å‘å°„æœ€ç»ˆäº‹ä»¶
                if self.on_speech_segment:
                    try:
                        self.on_speech_segment(speech_segment)
                    except Exception as e:
                        logger.error(f"æœ€ç»ˆäº‹ä»¶å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
            
            # å¼ºåˆ¶åˆ·æ–°VADçŠ¶æ€ï¼Œç¡®ä¿æ‰€æœ‰ç¼“å†²çš„ç»“æœéƒ½è¢«è¾“å‡º
            try:
                # å‘é€ä¸€ä¸ªé™éŸ³å—æ¥è§¦å‘ä»»ä½•å¾…å¤„ç†çš„ç»“æŸäº‹ä»¶
                silent_chunk = np.zeros(self.processing_chunk_size, dtype=np.float32)
                final_result = vad(silent_chunk, return_seconds=True)
                if final_result:
                    print(f"æœ€ç»ˆåˆ·æ–°ç»“æœ: {final_result}")
                    results.append(final_result)
            except Exception as e:
                print(f"æœ€ç»ˆåˆ·æ–°æ—¶å‡ºé”™: {e}")
        
        # æ ¹æ®éœ€è¦è¿”å›ä¸åŒæ ¼å¼
        if return_segments:
            return self._convert_to_segments(results)
        else:
            return results
    
    def _extract_audio_segment(self, start_sample: int, end_sample: int) -> bytes:
        """
        ä»éŸ³é¢‘ç¼“å­˜ä¸­æå–æŒ‡å®šèŒƒå›´çš„éŸ³é¢‘æ•°æ®
        
        Args:
            start_sample: å¼€å§‹æ ·æœ¬ä½ç½®
            end_sample: ç»“æŸæ ·æœ¬ä½ç½®
            
        Returns:
            éŸ³é¢‘æ•°æ®çš„å­—èŠ‚è¡¨ç¤º
        """
        try:
            # æ”¶é›†æŒ‡å®šèŒƒå›´å†…çš„éŸ³é¢‘æ•°æ®
            audio_segments = []
            current_sample = 0
            
            for audio_chunk, chunk_start_sample in self._audio_buffer:
                chunk_end_sample = chunk_start_sample + len(audio_chunk)
                
                # æ£€æŸ¥è¿™ä¸ªå—æ˜¯å¦ä¸ç›®æ ‡èŒƒå›´é‡å 
                if chunk_end_sample > start_sample and chunk_start_sample < end_sample:
                    # è®¡ç®—åœ¨è¿™ä¸ªå—å†…çš„ç›¸å¯¹ä½ç½®
                    relative_start = max(0, start_sample - chunk_start_sample)
                    relative_end = min(len(audio_chunk), end_sample - chunk_start_sample)
                    
                    # æå–ç›¸å…³éƒ¨åˆ†
                    segment = audio_chunk[relative_start:relative_end]
                    audio_segments.append(segment)
            
            if audio_segments:
                # åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ®µ
                combined_audio = np.concatenate(audio_segments)
                # è½¬æ¢ä¸ºå­—èŠ‚
                return combined_audio.astype(np.float32).tobytes()
            else:
                logger.warning(f"æ— æ³•æ‰¾åˆ°æ ·æœ¬èŒƒå›´ {start_sample}-{end_sample} çš„éŸ³é¢‘æ•°æ®")
                return b''
                
        except Exception as e:
            logger.error(f"æå–éŸ³é¢‘æ®µæ—¶å‡ºé”™: {e}")
            return b''
    
    def _convert_to_segments(self, vad_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å°†VADç»“æœè½¬æ¢ä¸ºè¯­éŸ³æ®µæ ¼å¼
        
        Args:
            vad_results: VADåŸå§‹ç»“æœ [{'start': float}, {'end': float}, ...]
            
        Returns:
            è¯­éŸ³æ®µåˆ—è¡¨ [{'start': float, 'end': float, 'duration': float}, ...]
        """
        segments = []
        start_time = None
        
        for result in vad_results:
            if 'start' in result:
                start_time = result['start']
            elif 'end' in result and start_time is not None:
                segments.append({
                    'start': start_time,
                    'end': result['end'],
                    'duration': result['end'] - start_time
                })
                start_time = None
        
        return segments


# ä¾¿åˆ©å‡½æ•°ï¼Œä¿æŒå‘åå…¼å®¹æ€§
def create_vac_processor(
    threshold: float = 0.3,
    min_silence_duration_ms: int = 300,
    speech_pad_ms: int = 100,
    sample_rate: int = 16000,
    on_speech_segment: Optional[Callable[[Dict[str, Any]], None]] = None
) -> VACProcessor:
    """
    åˆ›å»ºVACå¤„ç†å™¨çš„ä¾¿åˆ©å‡½æ•°
    
    Args:
        threshold: è¯­éŸ³æ£€æµ‹é˜ˆå€¼
        min_silence_duration_ms: æœ€å°é™éŸ³æŒç»­æ—¶é—´
        speech_pad_ms: è¯­éŸ³æ®µå¡«å……æ—¶é—´
        sample_rate: é‡‡æ ·ç‡
        on_speech_segment: è¯­éŸ³æ®µæ£€æµ‹å®Œæˆæ—¶çš„å›è°ƒå‡½æ•°
        
    Returns:
        VACProcessorå®ä¾‹
    """
    return VACProcessor(
        threshold=threshold,
        min_silence_duration_ms=min_silence_duration_ms,
        speech_pad_ms=speech_pad_ms,
        sample_rate=sample_rate,
        on_speech_segment=on_speech_segment
    )
