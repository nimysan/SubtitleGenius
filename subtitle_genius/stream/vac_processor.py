"""
Voice Activity Detection (VAD) å¤„ç†å™¨
åŸºäºSilero VADæ¨¡å‹çš„æµå¼è¯­éŸ³æ´»åŠ¨æ£€æµ‹
"""

import os
import sys
import time
import numpy as np
import torch
from typing import Iterator, List, Dict, Any, Optional
from loguru import logger

# æ·»åŠ whisper_streamingç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), 'whisper_streaming'))
from silero_vad_iterator import FixedVADIterator


class VACProcessor:
    """
    Voice Activity Detection å¤„ç†å™¨
    
    åŸºäºSilero VADæ¨¡å‹çš„æµå¼è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼Œæ”¯æŒå®æ—¶éŸ³é¢‘æµå¤„ç†
    """
    
    def __init__(
        self,
        threshold: float = 0.3,
        min_silence_duration_ms: int = 300,
        speech_pad_ms: int = 100,
        sample_rate: int = 16000,
        processing_chunk_size: int = 512,
        no_audio_input_threshold: float = 0.5
    ):
        """
        åˆå§‹åŒ–VACå¤„ç†å™¨
        
        Args:
            threshold: è¯­éŸ³æ£€æµ‹é˜ˆå€¼ (0.0-1.0)
            min_silence_duration_ms: æœ€å°é™éŸ³æŒç»­æ—¶é—´(ms)
            speech_pad_ms: è¯­éŸ³æ®µå¡«å……æ—¶é—´(ms)
            sample_rate: éŸ³é¢‘é‡‡æ ·ç‡
            processing_chunk_size: å¤„ç†å—å¤§å°ï¼Œå¿…é¡»æ˜¯512çš„æ•´æ•°å€
            no_audio_input_threshold: æ— éŸ³é¢‘è¾“å…¥é˜ˆå€¼(ç§’)
        """
        self.threshold = threshold
        self.min_silence_duration_ms = min_silence_duration_ms
        self.speech_pad_ms = speech_pad_ms
        self.sample_rate = sample_rate
        self.processing_chunk_size = processing_chunk_size
        self.no_audio_input_threshold = no_audio_input_threshold
        
        # éªŒè¯å¤„ç†å—å¤§å°
        if self.processing_chunk_size % 512 != 0:
            raise ValueError(
                f"processing_chunk_sizeå¿…é¡»æ˜¯512çš„æ•´æ•°å€ï¼å½“å‰å€¼ä¸º{self.processing_chunk_size}ã€‚"
                f"æ¨èå€¼ï¼š512, 1024, 1536, 2048ç­‰ã€‚"
            )
        
        # åˆå§‹åŒ–æ¨¡å‹å’ŒVADè¿­ä»£å™¨
        self._model = None
        self._vad_iterator = None
        
        logger.info(f"VACProcessor initialized with parameters:")
        logger.info(f"  threshold: {self.threshold}")
        logger.info(f"  min_silence_duration_ms: {self.min_silence_duration_ms}")
        logger.info(f"  speech_pad_ms: {self.speech_pad_ms}")
        logger.info(f"  sample_rate: {self.sample_rate}")
        logger.info(f"  processing_chunk_size: {self.processing_chunk_size}")
        logger.info(f"  no_audio_input_threshold: {self.no_audio_input_threshold}")
    
    def _load_model(self):
        """åŠ è½½Silero VADæ¨¡å‹"""
        if self._model is None:
            logger.info("Loading Silero VAD model...")
            self._model, _ = torch.hub.load(
                repo_or_dir='snakers4/silero-vad',
                model='silero_vad'
            )
            logger.info("Silero VAD model loaded successfully")
        return self._model
    
    def _create_vad_iterator(self):
        """åˆ›å»ºVADè¿­ä»£å™¨"""
        if self._vad_iterator is None:
            model = self._load_model()
            self._vad_iterator = FixedVADIterator(
                model=model,
                threshold=self.threshold,
                sampling_rate=self.sample_rate,
                min_silence_duration_ms=self.min_silence_duration_ms,
                speech_pad_ms=self.speech_pad_ms
            )
            logger.info("VAD iterator created successfully")
        return self._vad_iterator
    
    def reset_vad_state(self):
        """é‡ç½®VADçŠ¶æ€"""
        if self._vad_iterator is not None:
            self._vad_iterator.reset_states()
            logger.debug("VAD state reset")
    
    def process_streaming_audio(
        self, 
        audio_stream: Iterator[np.ndarray],
        return_segments: bool = True
    ) -> List[Dict[str, Any]]:
        """
        å¤„ç†æµå¼éŸ³é¢‘æ•°æ®ï¼Œè¿›è¡Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹
        
        Args:
            audio_stream: éŸ³é¢‘æµè¿­ä»£å™¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯numpyæ•°ç»„
            return_segments: æ˜¯å¦è¿”å›è¯­éŸ³æ®µæ ¼å¼ï¼ˆåŒ…å«startã€endã€durationï¼‰
            
        Returns:
            è¯­éŸ³æ£€æµ‹ç»“æœåˆ—è¡¨
            - å¦‚æœreturn_segments=True: [{'start': float, 'end': float, 'duration': float}, ...]
            - å¦‚æœreturn_segments=False: [{'start': float}, {'end': float}, ...]
        """
        logger.info("å¼€å§‹æµå¼VADå¤„ç†")
        logger.info(f"ä¸ºé¿å…VADæ—¶é—´æˆ³è†¨èƒ€é—®é¢˜ï¼Œè¯·ç¡®ä¿éŸ³é¢‘æµä¸­çš„å—å¤§å°æ˜¯512çš„æ•´æ•°å€")
        
        # åˆ›å»ºVADè¿­ä»£å™¨
        vad = self._create_vad_iterator()
        
        # å¤„ç†å˜é‡
        results = []
        last_audio_time = time.time()
        total_samples_processed = 0
        stream_ended = False
        
        logger.info(f"å¼€å§‹å¤„ç†éŸ³é¢‘æµï¼Œå‚æ•°:")
        logger.info(f"  threshold={self.threshold}")
        logger.info(f"  min_silence_duration_ms={self.min_silence_duration_ms}")
        logger.info(f"  speech_pad_ms={self.speech_pad_ms}")
        logger.info(f"  no_audio_input_threshold={self.no_audio_input_threshold}ç§’")
        
        try:
            # å¤„ç†æµå¼éŸ³é¢‘
            for audio_chunk in audio_stream:
                # æ›´æ–°æœ€åæ¥æ”¶éŸ³é¢‘çš„æ—¶é—´
                last_audio_time = time.time()
                
                # å¤„ç†éŸ³é¢‘å—
                for i in range(0, len(audio_chunk), self.processing_chunk_size):
                    chunk = audio_chunk[i:i+self.processing_chunk_size]
                    
                    # å¦‚æœéœ€è¦ï¼Œç”¨é›¶å¡«å……
                    print(f"------->len of chunk is {len(chunk)} and processing chunk size is {self.processing_chunk_size}")
                    if len(chunk) < self.processing_chunk_size:
                        chunk = np.pad(chunk, (0, self.processing_chunk_size - len(chunk)), 'constant')
                    
                    # ä½¿ç”¨VADè¿­ä»£å™¨å¤„ç†å—
                    result = vad(chunk, return_seconds=True)
                    
                    total_samples_processed += len(chunk)
                    
                    if result:
                        print(f"---vad result is {result}")
                        results.append(result)
                
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æ— éŸ³é¢‘è¾“å…¥é˜ˆå€¼
                if time.time() - last_audio_time > self.no_audio_input_threshold:
                    stream_ended = True
                    break
            
            # æ ‡è®°æµå·²ç»“æŸ
            stream_ended = True
            
        except Exception as e:
            print(f"æµå¤„ç†ä¸­æ–­: {e}")
            stream_ended = True
        
        # ğŸ”§ ä¿®å¤ï¼šéŸ³é¢‘æµç»“æŸæ—¶çš„å¤„ç†
        if stream_ended:
            print(f"éŸ³é¢‘æµå·²ç»“æŸï¼Œæ­£åœ¨è¿›è¡Œæœ€ç»ˆå¤„ç†...")
            
            # å¦‚æœVADä»å¤„äºè§¦å‘çŠ¶æ€ï¼Œå¼ºåˆ¶ç»“æŸå½“å‰è¯­éŸ³æ®µ
            if vad.triggered:
                # ä½¿ç”¨å½“å‰å¤„ç†çš„æ€»æ ·æœ¬æ•°è®¡ç®—ç»“æŸæ—¶é—´
                end_time = total_samples_processed / self.sample_rate
                results.append({'end': end_time})
                print(f"æ£€æµ‹åˆ°æœªç»“æŸçš„è¯­éŸ³æ®µï¼Œå¼ºåˆ¶ç»“æŸäº {end_time:.2f}ç§’")
            
            # å¼ºåˆ¶åˆ·æ–°VADçŠ¶æ€ï¼Œç¡®ä¿æ‰€æœ‰ç¼“å†²çš„ç»“æœéƒ½è¢«è¾“å‡º
            try:
                # å‘é€ä¸€ä¸ªé™éŸ³å—æ¥è§¦å‘ä»»ä½•å¾…å¤„ç†çš„ç»“æŸäº‹ä»¶
                silent_chunk = np.zeros(self.processing_chunk_size, dtype=np.float32)
                final_result = vad(silent_chunk, return_seconds=True)
                if final_result:
                    print(f"æœ€ç»ˆåˆ·æ–°ç»“æœ: {final_result}")
                    results.append(final_result)
            except Exception as e:
                print(f"æœ€ç»ˆåˆ·æ–°æ—¶å‡ºé”™: {e}")
        
        # æ ¹æ®éœ€è¦è¿”å›ä¸åŒæ ¼å¼
        if return_segments:
            return self._convert_to_segments(results)
        else:
            return results
    
    def _convert_to_segments(self, vad_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å°†VADç»“æœè½¬æ¢ä¸ºè¯­éŸ³æ®µæ ¼å¼
        
        Args:
            vad_results: VADåŸå§‹ç»“æœ [{'start': float}, {'end': float}, ...]
            
        Returns:
            è¯­éŸ³æ®µåˆ—è¡¨ [{'start': float, 'end': float, 'duration': float}, ...]
        """
        segments = []
        start_time = None
        
        for result in vad_results:
            if 'start' in result:
                start_time = result['start']
            elif 'end' in result and start_time is not None:
                segments.append({
                    'start': start_time,
                    'end': result['end'],
                    'duration': result['end'] - start_time
                })
                start_time = None
        
        return segments


# ä¾¿åˆ©å‡½æ•°ï¼Œä¿æŒå‘åå…¼å®¹æ€§
def create_vac_processor(
    threshold: float = 0.3,
    min_silence_duration_ms: int = 300,
    speech_pad_ms: int = 100,
    sample_rate: int = 16000
) -> VACProcessor:
    """
    åˆ›å»ºVACå¤„ç†å™¨çš„ä¾¿åˆ©å‡½æ•°
    
    Args:
        threshold: è¯­éŸ³æ£€æµ‹é˜ˆå€¼
        min_silence_duration_ms: æœ€å°é™éŸ³æŒç»­æ—¶é—´
        speech_pad_ms: è¯­éŸ³æ®µå¡«å……æ—¶é—´
        sample_rate: é‡‡æ ·ç‡
        
    Returns:
        VACProcessorå®ä¾‹
    """
    return VACProcessor(
        threshold=threshold,
        min_silence_duration_ms=min_silence_duration_ms,
        speech_pad_ms=speech_pad_ms,
        sample_rate=sample_rate
    )
