"""
Voice Activity Detection (VAD) å¤„ç†å™¨
åŸºäºSilero VADæ¨¡å‹çš„æµå¼è¯­éŸ³æ´»åŠ¨æ£€æµ‹
"""

import os
import sys
import time
import numpy as np
import torch
import logging
from typing import Iterator, List, Dict, Any, Optional, Callable
from loguru import logger
from collections import deque

# æ·»åŠ whisper_streamingç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), 'whisper_streaming'))
from silero_vad_iterator import FixedVADIterator
# é…ç½®æ—¥å¿—

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("subtitle_genius.stream.vac_processor")

class VACProcessor:
    """
    Voice Activity Detection å¤„ç†å™¨
    
    åŸºäºSilero VADæ¨¡å‹çš„æµå¼è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼Œæ”¯æŒå®æ—¶éŸ³é¢‘æµå¤„ç†
    """
    
    def __init__(
        self,
        threshold: float = 0.5,
        min_silence_duration_ms: int = 300,
        speech_pad_ms: int = 100,
        sample_rate: int = 16000,
        processing_chunk_size: int = 512,
        no_audio_input_threshold: float = 5,
        buffer_duration: float = 60.0,  # ç¼“å†²åŒºä¿ç•™çš„éŸ³é¢‘æ—¶é•¿(ç§’)
        on_speech_segment: Optional[Callable[[Dict[str, Any]], None]] = None
    ):
        """
        åˆå§‹åŒ–VACå¤„ç†å™¨
        
        Args:
            threshold: è¯­éŸ³æ£€æµ‹é˜ˆå€¼ (0.0-1.0)
            min_silence_duration_ms: æœ€å°é™éŸ³æŒç»­æ—¶é—´(ms)
            speech_pad_ms: è¯­éŸ³æ®µå¡«å……æ—¶é—´(ms)
            sample_rate: éŸ³é¢‘é‡‡æ ·ç‡
            processing_chunk_size: å¤„ç†å—å¤§å°ï¼Œå¿…é¡»æ˜¯512çš„æ•´æ•°å€
            no_audio_input_threshold: æ— éŸ³é¢‘è¾“å…¥é˜ˆå€¼(ç§’)
            buffer_duration: éŸ³é¢‘ç¼“å†²åŒºä¿ç•™çš„æ—¶é•¿(ç§’)
            on_speech_segment: è¯­éŸ³æ®µæ£€æµ‹å®Œæˆæ—¶çš„å›è°ƒå‡½æ•°
        """
        self.threshold = threshold
        self.min_silence_duration_ms = min_silence_duration_ms
        self.speech_pad_ms = speech_pad_ms
        self.sample_rate = sample_rate
        self.processing_chunk_size = processing_chunk_size
        self.no_audio_input_threshold = no_audio_input_threshold
        self.buffer_duration = buffer_duration
        self.on_speech_segment = on_speech_segment
        
        # éªŒè¯å¤„ç†å—å¤§å°
        if self.processing_chunk_size % 512 != 0:
            raise ValueError(
                f"processing_chunk_sizeå¿…é¡»æ˜¯512çš„æ•´æ•°å€ï¼å½“å‰å€¼ä¸º{self.processing_chunk_size}ã€‚"
                f"æ¨èå€¼ï¼š512, 1024, 1536, 2048ç­‰ã€‚"
            )
        
        # åˆå§‹åŒ–æ¨¡å‹å’ŒVADè¿­ä»£å™¨
        self._model = None
        self._vad_iterator = None
        
        # éŸ³é¢‘ç¼“å­˜å’ŒçŠ¶æ€è·Ÿè¸ª
        # è®¡ç®—ç¼“å†²åŒºæœ€å¤§é•¿åº¦ (åŸºäºæ—¶é—´å’Œé‡‡æ ·ç‡)
        max_buffer_samples = int(self.buffer_duration * self.sample_rate)
        max_buffer_chunks = max_buffer_samples // self.processing_chunk_size + 10  # é¢å¤–ç©ºé—´é˜²æ­¢è¾¹ç•Œé—®é¢˜
        self._audio_buffer = deque(maxlen=max_buffer_chunks)  # å­˜å‚¨éŸ³é¢‘æ•°æ®ï¼Œé™åˆ¶æœ€å¤§é•¿åº¦
        self._current_start_time = None  # å½“å‰è¯­éŸ³æ®µçš„å¼€å§‹æ—¶é—´
        self._current_start_sample = None  # å½“å‰è¯­éŸ³æ®µçš„å¼€å§‹æ ·æœ¬ä½ç½®
        
        logger.info(f"VACProcessor initialized with parameters:")
        logger.info(f"  threshold: {self.threshold}")
        logger.info(f"  min_silence_duration_ms: {self.min_silence_duration_ms}")
        logger.info(f"  speech_pad_ms: {self.speech_pad_ms}")
        logger.info(f"  sample_rate: {self.sample_rate}")
        logger.info(f"  processing_chunk_size: {self.processing_chunk_size}")
        logger.info(f"  no_audio_input_threshold: {self.no_audio_input_threshold}")
        logger.info(f"  buffer_duration: {self.buffer_duration}ç§’ (çº¦ {max_buffer_samples} ä¸ªæ ·æœ¬)")
    
    def _load_model(self):
        """åŠ è½½Silero VADæ¨¡å‹"""
        if self._model is None:
            logger.info("Loading Silero VAD model...")
            self._model, _ = torch.hub.load(
                repo_or_dir='snakers4/silero-vad',
                model='silero_vad'
            )
            logger.info("Silero VAD model loaded successfully")
        return self._model
    
    def _create_vad_iterator(self):
        """åˆ›å»ºVADè¿­ä»£å™¨"""
        if self._vad_iterator is None:
            model = self._load_model()
            self._vad_iterator = FixedVADIterator(
                model=model,
                threshold=self.threshold,
                sampling_rate=self.sample_rate,
                min_silence_duration_ms=self.min_silence_duration_ms,
                speech_pad_ms=self.speech_pad_ms
            )
            logger.info("VAD iterator created successfully")
        return self._vad_iterator
    
    def reset_vad_state(self):
        """é‡ç½®VADçŠ¶æ€"""
        if self._vad_iterator is not None:
            self._vad_iterator.reset_states()
            logger.debug("VAD state reset")
    
    def process_streaming_audio(
        self, 
        audio_stream: Iterator[np.ndarray],
        end_stream_flag: bool = True,
        return_segments: bool = True
    ) -> List[Dict[str, Any]]:
        """
        å¤„ç†æµå¼éŸ³é¢‘æ•°æ®ï¼Œè¿›è¡Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹
        
        Args:
            audio_stream: éŸ³é¢‘æµè¿­ä»£å™¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯numpyæ•°ç»„
            end_stream_flag: æ˜¯å¦åœ¨å¤„ç†å®Œæ‰€æœ‰æ•°æ®åæ ‡è®°æµç»“æŸ
            return_segments: æ˜¯å¦è¿”å›è¯­éŸ³æ®µæ ¼å¼ï¼ˆåŒ…å«startã€endã€durationï¼‰
            
        Returns:
            è¯­éŸ³æ£€æµ‹ç»“æœåˆ—è¡¨
            - å¦‚æœreturn_segments=True: [{'start': float, 'end': float, 'duration': float}, ...]
            - å¦‚æœreturn_segments=False: [{'start': float}, {'end': float}, ...]
        """
        logger.info("å¼€å§‹æµå¼VADå¤„ç†")
        logger.info(f"ä¸ºé¿å…VADæ—¶é—´æˆ³è†¨èƒ€é—®é¢˜ï¼Œè¯·ç¡®ä¿éŸ³é¢‘æµä¸­çš„å—å¤§å°æ˜¯512çš„æ•´æ•°å€")
        
        # åˆ›å»ºVADè¿­ä»£å™¨
        vad = self._create_vad_iterator()
        
        # å¤„ç†å˜é‡
        results = []
        last_audio_time = time.time()
        total_samples_processed = 0
        stream_ended = False
        
        # é‡ç½®éŸ³é¢‘ç¼“å­˜å’ŒçŠ¶æ€
        self._audio_buffer.clear()
        self._current_start_time = None
        self._current_start_sample = None
        
        logger.info(f"å¼€å§‹å¤„ç†éŸ³é¢‘æµï¼Œå‚æ•°:")
        logger.info(f"  threshold={self.threshold}")
        logger.info(f"  min_silence_duration_ms={self.min_silence_duration_ms}")
        logger.info(f"  speech_pad_ms={self.speech_pad_ms}")
        logger.info(f"  no_audio_input_threshold={self.no_audio_input_threshold}ç§’")
        logger.info(f"  buffer_duration={self.buffer_duration}ç§’")
        
        try:
            # å¤„ç†æµå¼éŸ³é¢‘
            for audio_chunk in audio_stream:
                # æ›´æ–°æœ€åæ¥æ”¶éŸ³é¢‘çš„æ—¶é—´
                last_audio_time = time.time()
                
                # å°†éŸ³é¢‘å—æ·»åŠ åˆ°ç¼“å­˜
                self._audio_buffer.append((audio_chunk.copy(), total_samples_processed))
                
                # æ¸…ç†è¿‡æ—§çš„ç¼“å†²åŒºæ•°æ®ï¼Œä¿æŒå†…å­˜ä½¿ç”¨åˆç†
                current_time = total_samples_processed / self.sample_rate
                buffer_start_time = current_time - self.buffer_duration
                
                # åªæœ‰å½“ç¼“å†²åŒºæ¥è¿‘æ»¡æ—¶æ‰æ¸…ç†ï¼Œé¿å…é¢‘ç¹æ“ä½œ
                if len(self._audio_buffer) > self._audio_buffer.maxlen * 0.8:
                    # è®¡ç®—è¦ä¿ç•™çš„æœ€æ—©æ ·æœ¬ä½ç½®
                    earliest_sample_to_keep = int(buffer_start_time * self.sample_rate)
                    
                    # ç§»é™¤è¿‡æ—§çš„æ•°æ®
                    while (self._audio_buffer and 
                           self._audio_buffer[0][1] + len(self._audio_buffer[0][0]) < earliest_sample_to_keep):
                        old_chunk = self._audio_buffer.popleft()
                        logger.debug(f"ç§»é™¤è¿‡æ—§çš„éŸ³é¢‘å—: {old_chunk[1]}-{old_chunk[1]+len(old_chunk[0])}")
                
                # å¤„ç†éŸ³é¢‘å—
                for i in range(0, len(audio_chunk), self.processing_chunk_size):
                    chunk = audio_chunk[i:i+self.processing_chunk_size]
                    
                    # å¦‚æœéœ€è¦ï¼Œç”¨é›¶å¡«å……
                    if len(chunk) < self.processing_chunk_size:
                        chunk = np.pad(chunk, (0, self.processing_chunk_size - len(chunk)), 'constant')
                    
                    # ä½¿ç”¨VADè¿­ä»£å™¨å¤„ç†å—
                    result = vad(chunk, return_seconds=True)
                    # logger.info(f"----======--->>>vad result is {result}")
                    total_samples_processed += len(chunk)
                    
                    if result:
                        # logger.info(f"------->>>vad result is {result}")
                        results.append(result)
                        
                        # ğŸ¯ å…³é”®é€»è¾‘ï¼šå¤„ç†startå’Œendäº‹ä»¶
                        if 'start' in result:
                            # åªæœ‰åœ¨æ²¡æœ‰æ´»è·ƒè¯­éŸ³æ®µæ—¶æ‰è®°å½•æ–°çš„å¼€å§‹
                            if self._current_start_time is None:
                                self._current_start_time = result['start']
                                self._current_start_sample = int(result['start'] * self.sample_rate)
                                logger.info(f"æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹: {self._current_start_time:.2f}s")
                            else:
                                # å¦‚æœå·²ç»æœ‰æ´»è·ƒçš„è¯­éŸ³æ®µï¼Œå¿½ç•¥æ–°çš„startäº‹ä»¶
                                logger.debug(f"å¿½ç•¥é‡å¤çš„startäº‹ä»¶: {result['start']:.2f}s (å½“å‰æ´»è·ƒæ®µ: {self._current_start_time:.2f}s)")
                            
                        elif 'end' in result and self._current_start_time is not None:
                            # æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼Œå‘å°„äº‹ä»¶
                            end_time = result['end']
                            end_sample = int(end_time * self.sample_rate)
                            
                            # æå–å¯¹åº”çš„éŸ³é¢‘æ•°æ®
                            audio_bytes, audio_metadata = self._extract_audio_segment(
                                self._current_start_sample, 
                                end_sample
                            )
                            
                            # åˆ›å»ºè¯­éŸ³æ®µäº‹ä»¶æ•°æ®
                            speech_segment = {
                                'start': self._current_start_time,
                                'end': end_time,
                                'duration': end_time - self._current_start_time,
                                'audio_bytes': audio_bytes,
                                'sample_rate': self.sample_rate,
                                'audio_format': 'float32',
                                'num_channels': 1,
                                'audio_metadata': audio_metadata
                            }
                            
                            logger.info(f"æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ: {end_time:.2f}s, æ—¶é•¿: {speech_segment['duration']:.2f}s, " +
                                       f"éŸ³é¢‘å®Œæ•´æ€§: {audio_metadata['completeness']:.1f}%")
                            
                            # ğŸš€ å‘å°„äº‹ä»¶ - ç¡®ä¿åªè§¦å‘ä¸€æ¬¡
                            if self.on_speech_segment:
                                try:
                                    self.on_speech_segment(speech_segment)
                                    logger.debug(f"âœ… è¯­éŸ³æ®µäº‹ä»¶å·²è§¦å‘: {self._current_start_time:.2f}s-{end_time:.2f}s")
                                except Exception as e:
                                    logger.error(f"äº‹ä»¶å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
                                    import traceback
                                    logger.error(traceback.format_exc())
                            
                            # ğŸ”§ é‡è¦ï¼šç«‹å³é‡ç½®çŠ¶æ€ï¼Œé˜²æ­¢é‡å¤è§¦å‘
                            self._current_start_time = None
                            self._current_start_sample = None
                            
                        elif 'end' in result and self._current_start_time is None:
                            # æ”¶åˆ°endäº‹ä»¶ä½†æ²¡æœ‰å¯¹åº”çš„startäº‹ä»¶ï¼Œè®°å½•è­¦å‘Š
                            logger.warning(f"æ”¶åˆ°å­¤ç«‹çš„endäº‹ä»¶: {result['end']:.2f}s (æ²¡æœ‰å¯¹åº”çš„startäº‹ä»¶)")
                
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æ— éŸ³é¢‘è¾“å…¥é˜ˆå€¼
                if time.time() - last_audio_time > self.no_audio_input_threshold:
                    logger.warning(f"è¶…è¿‡æ— éŸ³é¢‘è¾“å…¥é˜ˆå€¼ ({self.no_audio_input_threshold}ç§’)ï¼Œæ ‡è®°æµç»“æŸ")
                    stream_ended = True
                    break
            
            # æ ‡è®°æµå·²ç»“æŸ
            if end_stream_flag:
                logger.info("end_stream_flagä¸ºTrueï¼Œæ ‡è®°æµç»“æŸ")
                stream_ended = True
            
        except Exception as e:
            logger.error(f"æµå¤„ç†ä¸­æ–­: {e}")
            import traceback
            logger.error(traceback.format_exc())
            stream_ended = True
        
        # ğŸ”§ ä¿®å¤ï¼šéŸ³é¢‘æµç»“æŸæ—¶çš„å¤„ç†
        if stream_ended:
            logger.info(f"éŸ³é¢‘æµå·²ç»“æŸï¼Œæ­£åœ¨è¿›è¡Œæœ€ç»ˆå¤„ç†...")
            
            # å¦‚æœVADä»å¤„äºè§¦å‘çŠ¶æ€ï¼Œå¼ºåˆ¶ç»“æŸå½“å‰è¯­éŸ³æ®µ
            if vad.triggered and self._current_start_time is not None:
                # ä½¿ç”¨å½“å‰å¤„ç†çš„æ€»æ ·æœ¬æ•°è®¡ç®—ç»“æŸæ—¶é—´
                end_time = total_samples_processed / self.sample_rate
                end_sample = total_samples_processed
                
                # æå–éŸ³é¢‘æ•°æ®
                audio_bytes, audio_metadata = self._extract_audio_segment(
                    self._current_start_sample, 
                    end_sample
                )
                
                # åˆ›å»ºè¯­éŸ³æ®µäº‹ä»¶æ•°æ®
                speech_segment = {
                    'start': self._current_start_time,
                    'end': end_time,
                    'duration': end_time - self._current_start_time,
                    'audio_bytes': audio_bytes,
                    'sample_rate': self.sample_rate,
                    'audio_format': 'float32',
                    'num_channels': 1,
                    'audio_metadata': audio_metadata,
                    'is_final': True
                }
                
                results.append({'end': end_time})
                logger.info(f"æ£€æµ‹åˆ°æœªç»“æŸçš„è¯­éŸ³æ®µï¼Œå¼ºåˆ¶ç»“æŸäº {end_time:.2f}ç§’, " +
                           f"éŸ³é¢‘å®Œæ•´æ€§: {audio_metadata['completeness']:.1f}%")
                
                # ğŸš€ å‘å°„æœ€ç»ˆäº‹ä»¶
                if self.on_speech_segment:
                    try:
                        self.on_speech_segment(speech_segment)
                        logger.info(f"âœ… æœ€ç»ˆè¯­éŸ³æ®µäº‹ä»¶å·²è§¦å‘: {self._current_start_time:.2f}s-{end_time:.2f}s")
                    except Exception as e:
                        logger.error(f"æœ€ç»ˆäº‹ä»¶å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
                        import traceback
                        logger.error(traceback.format_exc())
            
            # å¼ºåˆ¶åˆ·æ–°VADçŠ¶æ€ï¼Œç¡®ä¿æ‰€æœ‰ç¼“å†²çš„ç»“æœéƒ½è¢«è¾“å‡º
            try:
                # å‘é€ä¸€ä¸ªé™éŸ³å—æ¥è§¦å‘ä»»ä½•å¾…å¤„ç†çš„ç»“æŸäº‹ä»¶
                silent_chunk = np.zeros(self.processing_chunk_size, dtype=np.float32)
                final_result = vad(silent_chunk, return_seconds=True)
                if final_result:
                    logger.info(f"æœ€ç»ˆåˆ·æ–°ç»“æœ: {final_result}")
                    results.append(final_result)
            except Exception as e:
                logger.error(f"æœ€ç»ˆåˆ·æ–°æ—¶å‡ºé”™: {e}")
        
        # æ ¹æ®éœ€è¦è¿”å›ä¸åŒæ ¼å¼
        if return_segments:
            return self._convert_to_segments(results)
        else:
            return results
    
    def _extract_audio_segment(self, start_sample: int, end_sample: int) -> bytes:
        """
        ä»éŸ³é¢‘ç¼“å­˜ä¸­æå–æŒ‡å®šèŒƒå›´çš„éŸ³é¢‘æ•°æ®ï¼Œç¡®ä¿å®Œæ•´æ€§
        
        Args:
            start_sample: å¼€å§‹æ ·æœ¬ä½ç½®
            end_sample: ç»“æŸæ ·æœ¬ä½ç½®
                
        Returns:
            éŸ³é¢‘æ•°æ®çš„å­—èŠ‚è¡¨ç¤º
        """
        try:
            # æ”¶é›†æŒ‡å®šèŒƒå›´å†…çš„éŸ³é¢‘æ•°æ®
            audio_segments = []
            samples_found = 0
            required_samples = end_sample - start_sample
            
            # è®°å½•æå–è¿‡ç¨‹
            logger.debug(f"æå–éŸ³é¢‘æ®µ: {start_sample}-{end_sample}, éœ€è¦ {required_samples} ä¸ªæ ·æœ¬")
            
            for audio_chunk, chunk_start_sample in self._audio_buffer:
                chunk_end_sample = chunk_start_sample + len(audio_chunk)
                
                # æ£€æŸ¥è¿™ä¸ªå—æ˜¯å¦ä¸ç›®æ ‡èŒƒå›´é‡å 
                if chunk_end_sample > start_sample and chunk_start_sample < end_sample:
                    # è®¡ç®—åœ¨è¿™ä¸ªå—å†…çš„ç›¸å¯¹ä½ç½®
                    relative_start = max(0, start_sample - chunk_start_sample)
                    relative_end = min(len(audio_chunk), end_sample - chunk_start_sample)
                    
                    # æå–ç›¸å…³éƒ¨åˆ†
                    segment = audio_chunk[relative_start:relative_end]
                    audio_segments.append(segment)
                    samples_found += len(segment)
                    
                    logger.debug(f"ä»å— {chunk_start_sample}-{chunk_end_sample} æå–äº† {len(segment)} ä¸ªæ ·æœ¬")
            
            if audio_segments:
                # åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ®µ
                combined_audio = np.concatenate(audio_segments)
                
                # æ£€æŸ¥æ˜¯å¦è·å–äº†è¶³å¤Ÿçš„æ ·æœ¬
                completeness = samples_found / required_samples * 100 if required_samples > 0 else 100
                logger.info(f"éŸ³é¢‘æ®µæå–å®Œæˆ: è·å–äº† {samples_found}/{required_samples} ä¸ªæ ·æœ¬ ({completeness:.1f}%)")
                
                # å¦‚æœæ ·æœ¬ä¸è¶³ï¼Œå¯ä»¥è€ƒè™‘å¡«å……æˆ–è®°å½•è­¦å‘Š
                if samples_found < required_samples:
                    logger.warning(f"éŸ³é¢‘æ®µä¸å®Œæ•´: ç¼ºå°‘ {required_samples - samples_found} ä¸ªæ ·æœ¬")
                    
                    # å¯é€‰: å¡«å……ç¼ºå¤±çš„æ ·æœ¬
                    if samples_found < required_samples * 0.8:  # å¦‚æœç¼ºå¤±è¶…è¿‡20%
                        padding = np.zeros(required_samples - samples_found, dtype=np.float32)
                        combined_audio = np.concatenate([combined_audio, padding])
                        logger.info(f"å·²å¡«å…… {len(padding)} ä¸ªé™éŸ³æ ·æœ¬")
                
                # è½¬æ¢ä¸ºå­—èŠ‚
                audio_bytes = combined_audio.astype(np.float32).tobytes()
                
                # æ·»åŠ å…ƒæ•°æ®
                metadata = {
                    'samples_found': samples_found,
                    'required_samples': required_samples,
                    'completeness': completeness,
                    'sample_rate': self.sample_rate,
                    'audio_format': 'float32',
                    'num_channels': 1
                }
                
                return audio_bytes, metadata
            else:
                logger.warning(f"æ— æ³•æ‰¾åˆ°æ ·æœ¬èŒƒå›´ {start_sample}-{end_sample} çš„éŸ³é¢‘æ•°æ®")
                return b'', {
                    'samples_found': 0,
                    'required_samples': required_samples,
                    'completeness': 0,
                    'sample_rate': self.sample_rate,
                    'audio_format': 'float32',
                    'num_channels': 1
                }
                
        except Exception as e:
            logger.error(f"æå–éŸ³é¢‘æ®µæ—¶å‡ºé”™: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return b'', {
                'samples_found': 0,
                'required_samples': required_samples if 'required_samples' in locals() else 0,
                'completeness': 0,
                'sample_rate': self.sample_rate,
                'audio_format': 'float32',
                'num_channels': 1,
                'error': str(e)
            }
    
    def _convert_to_segments(self, vad_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å°†VADç»“æœè½¬æ¢ä¸ºè¯­éŸ³æ®µæ ¼å¼
        
        Args:
            vad_results: VADåŸå§‹ç»“æœ [{'start': float}, {'end': float}, ...]
            
        Returns:
            è¯­éŸ³æ®µåˆ—è¡¨ [{'start': float, 'end': float, 'duration': float}, ...]
        """
        segments = []
        start_time = None
        
        for result in vad_results:
            if 'start' in result:
                start_time = result['start']
            elif 'end' in result and start_time is not None:
                segments.append({
                    'start': start_time,
                    'end': result['end'],
                    'duration': result['end'] - start_time
                })
                start_time = None
        
        return segments


# ä¾¿åˆ©å‡½æ•°ï¼Œä¿æŒå‘åå…¼å®¹æ€§
def create_vac_processor(
    threshold: float = 0.3,
    min_silence_duration_ms: int = 300,
    speech_pad_ms: int = 100,
    sample_rate: int = 16000,
    on_speech_segment: Optional[Callable[[Dict[str, Any]], None]] = None
) -> VACProcessor:
    """
    åˆ›å»ºVACå¤„ç†å™¨çš„ä¾¿åˆ©å‡½æ•°
    
    Args:
        threshold: è¯­éŸ³æ£€æµ‹é˜ˆå€¼
        min_silence_duration_ms: æœ€å°é™éŸ³æŒç»­æ—¶é—´
        speech_pad_ms: è¯­éŸ³æ®µå¡«å……æ—¶é—´
        sample_rate: é‡‡æ ·ç‡
        on_speech_segment: è¯­éŸ³æ®µæ£€æµ‹å®Œæˆæ—¶çš„å›è°ƒå‡½æ•°
        
    Returns:
        VACProcessorå®ä¾‹
    """
    return VACProcessor(
        threshold=threshold,
        min_silence_duration_ms=min_silence_duration_ms,
        speech_pad_ms=speech_pad_ms,
        sample_rate=sample_rate,
        on_speech_segment=on_speech_segment
    )
